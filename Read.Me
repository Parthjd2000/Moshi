ğŸ§  What is Moshi

Moshi is an open-source, real-time speech-to-speech AI model created by Kyutai Labs
.
Unlike traditional systems that convert speech to text and back to speech, Moshi directly understands and generates audio â€” allowing for natural, low-latency voice conversations.

It uses Mimi, Kyutaiâ€™s custom speech codec, to compress and decode audio efficiently.
This design lets Moshi respond in under 200 milliseconds, making it capable of interactive spoken dialogue without intermediate text steps.
In simple terms:

ğŸ—£ï¸ You talk â†’ ğŸ§  Moshi listens, thinks, and replies â†’ ğŸ”Š You hear its response â€” all in real time.

Moshi can be run locally or in Google Colab using a single command:

!pip install -U moshi gradio
!python -m moshi.server --hf-repo kyutai/moshika-pytorch-bf16 --gradio-tunnel

When you run this, Moshi launches a Gradio web interface where you can speak or type, and it replies with AI-generated speech.

ğŸš€ How to Run Moshi

You can run Moshi on any machine with Python 3.10+ and a GPU, or directly in Google Colab.
Install the required packages

!pip install -U moshi gradio

Start the Moshi web interface

!python -m moshi.server --hf-repo kyutai/moshika-pytorch-bf16 --gradio-tunnel

Wait for a few minutes while the model downloads and loads.
When you see a line like this in the output:
Running on public URL: https://xxxx.gradio.live
click that link to open the Moshi voice chat interface.
From the interface, you can:

ğŸ¤ Speak to Moshi using your microphone

ğŸ’¬ Type text or upload audio files

ğŸ”Š Hear Moshi respond in real time with generated speech

ğŸ’¡ Tip: If you get a â€œCUDA out of memoryâ€ error, switch to the lighter quantized model:

!python -m moshi.server --hf-repo kyutai/moshika-pytorch-q8 --gradio-tunnel
